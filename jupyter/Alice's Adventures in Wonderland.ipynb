{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Alice's Adventures in Wonderland* by Lewis Carroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from find_path import find_dir\n",
    "import os\n",
    "\n",
    "\n",
    "title = \"Alice's Adventures in Wonderland\"\n",
    "name = \"Alice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five words in Alice's Adventures in Wonderland:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>She</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count\n",
       "1  And    869\n",
       "2   To    724\n",
       "3    A    624\n",
       "4   It    595\n",
       "5  She    553"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = find_dir(name)\n",
    "unfiltered = f'{path}/{name}.csv'\n",
    "filtered = f'{path}/{name}_filtered.csv'\n",
    "\n",
    "top_unfiltered = pd.read_csv(unfiltered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "top_unfiltered.drop(top_unfiltered.index[0], inplace=True)\n",
    "\n",
    "print(f\"The top five words in {title}:\")\n",
    "top_unfiltered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top hundred ranked words (unfiltered list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.78%\n"
     ]
    }
   ],
   "source": [
    "one_hundred = top_unfiltered[:100]\n",
    "hundred_total = one_hundred[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'{str(hundred_total * 100)[:5]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overall of the 100 words: 3.92%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage overall of the 100 words: {str(((len(one_hundred)/len(top_unfiltered))*100))[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words needed for ~80% comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 350 words (rounded to nearest 25) to reach 79.09% comprehension.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Witness</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Walked</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Those</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Tears</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Soldiers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Count\n",
       "346   Witness     10\n",
       "347    Walked     10\n",
       "348     Those     10\n",
       "349     Tears     10\n",
       "350  Soldiers     10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighty = top_unfiltered[:350]\n",
    "words = 350\n",
    "eighty_total = eighty[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'It takes {words} words (rounded to nearest 25) to reach {str(eighty_total * 100)[:5]}% comprehension.')\n",
    "eighty.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the 350 words in book: 13.7%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of the {words} words in book: {str((len(eighty)/len(top_unfiltered))*100)[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to transfer that to our filtered list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  Count\n",
      "311      Bird     11\n",
      "312       Ask     11\n",
      "313  Yourself     10\n",
      "314   Witness     10\n",
      "315    Walked     10\n"
     ]
    }
   ],
   "source": [
    "top = pd.read_csv(filtered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "#print(top.loc[top['Word']=='Walked'])\n",
    "vocab = top[:316]\n",
    "print(vocab.tail())\n",
    "vocab_hundred = vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons to Modern English words (according to Google's n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Alice's Adventures in Wonderland words NOT in 100 Top Modern English Words: \n",
      "\n",
      "['She', 'Said', 'Her', 'Had', 'Very', 'Little', 'Down', 'Then', 'Know', 'Them', 'Could', 'Went', 'Herself', 'Again', 'Thing', 'Thought', 'Did', 'Into', 'Off', 'Head', 'Began', 'Way', 'Quite', 'Think', 'Don', 'Say', 'Much', 'Voice', 'Go', 'Looked', 'Just', 'Got', 'Never', 'Must', 'Him', 'Round', 'Why']\n"
     ]
    }
   ],
   "source": [
    "n_path = find_dir('Ngram/edited_n_gram.csv')\n",
    "n_gram = pd.read_csv(n_path, names = [\"drop\", \"Word\", \"Count\"])\n",
    "n_gram.drop([\"drop\"], axis=1, inplace=True)\n",
    "n_gram.drop(index=[0], inplace=True)\n",
    "n_hundred= n_gram[:100]\n",
    "x = vocab_hundred.assign(hundred_in=vocab_hundred.Word.isin(n_hundred.Word).astype(int))\n",
    "h = x[x[\"hundred_in\"] == 0]\n",
    "h = list(h[\"Word\"].unique())\n",
    "h.remove(\"Ll\")\n",
    "h.remove(\"Ve\")\n",
    "print(f'Top 100 {title} words NOT in 100 Top Modern English Words: \\n\\n{h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice's Adventures in Wonderland Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \n",
      "\n",
      " ['Went', 'Herself', 'Began', 'Quite', 'Don', 'Voice', 'Looked', 'Round', 'Tone', 'Came', 'Re', 'Door', 'Moment', 'Heard', 'Dear', 'Nothing', 'Eyes', 'Seemed', 'Won', 'Rather', 'Poor', 'Took', 'Soon', 'Cry', 'Cat', 'Felt', 'Hurry', 'Wish', 'Till', 'Minute', 'Arm', 'Jury', 'Feet', 'Eat', 'Curious', 'Anything', 'Wonder', 'Tea', 'Spoke', 'Sat', 'Asked', 'Turned', 'Talking', 'Ran', 'Hastily', 'Doesn', 'Begin', 'Saying', 'Pig', 'Knew', 'Indeed', 'Idea', 'Gave', 'Trying', 'Sea', 'Saw', 'Perhap', 'Ought', 'Mouth', 'Mad', 'Itself', 'Hear', 'Beginning', 'Anxiously', 'Speak', 'Seem', 'Remark', 'Lesson', 'Kept', 'Happen', 'Grow', 'Gone', 'Dance', 'Cook', 'Certainly', 'Behind', 'Turning', 'Tail', 'Suppose', 'Suddenly', 'Queer', 'Mouse', 'Finished', 'Deal', 'Afraid', 'Wasn', 'Waited', 'Soldier', 'Sister', 'Silence', 'Matter', 'Hardly', 'Growing', 'Gloves', 'Glad', 'Ear', 'Conversation', 'Bird', 'Yourself', 'Witness', 'Walked']\n"
     ]
    }
   ],
   "source": [
    "y = vocab.assign(vocab_in=vocab.Word.isin(n_gram.Word).astype(int))\n",
    "t = y[y[\"vocab_in\"] == 0]\n",
    "t = list(t[\"Word\"].unique())\n",
    "t.remove(\"Ll\")\n",
    "t.remove(\"Ve\")\n",
    "print(f'{title} Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \\n\\n {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(t).to_csv(f'{path}/{name}_jupyter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab list: 101\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocab list: {len(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall word count of book: 26045\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall word count of book: {top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.79 3.92 350 79.09 101 26045\n"
     ]
    }
   ],
   "source": [
    "print(f'{str(round(hundred_total * 100, 2))}', f'{str(round((len(one_hundred)/len(top_unfiltered))*100, 2))}', words, f'{str(round(eighty_total * 100, 2))}', f'{len(t)}', f'{top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouth 364    10\n",
      "Name: Count, dtype: int64\n",
      "Lips 1981    1\n",
      "Name: Count, dtype: int64\n",
      "Head 98    50\n",
      "Name: Count, dtype: int64\n",
      "Face 248    15\n",
      "Name: Count, dtype: int64\n",
      "Hair 509    7\n",
      "Name: Count, dtype: int64\n",
      "Eyes 157    29\n",
      "Name: Count, dtype: int64\n",
      "Eye 520    7\n",
      "Name: Count, dtype: int64\n",
      "Ear 584    6\n",
      "Name: Count, dtype: int64\n",
      "Ears 667    5\n",
      "Name: Count, dtype: int64\n",
      "Butt Series([], Name: Count, dtype: int64)\n",
      "Ass Series([], Name: Count, dtype: int64)\n",
      "Feet 206    19\n",
      "Name: Count, dtype: int64\n",
      "Foot 403    9\n",
      "Name: Count, dtype: int64\n",
      "Leg Series([], Name: Count, dtype: int64)\n",
      "Legs 942    3\n",
      "Name: Count, dtype: int64\n",
      "Hand 197    21\n",
      "Name: Count, dtype: int64\n",
      "Hands 314    12\n",
      "Name: Count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "body = [\"Mouth\", \"Lips\", \"Head\", \"Face\", \"Hair\", \"Eyes\", \"Eye\", \"Ear\", \"Ears\", \"Butt\", \"Ass\", \"Feet\", \"Foot\", \"Leg\", \"Legs\", \"Hand\", \"Hands\"]\n",
    "\n",
    "for part in body:\n",
    "    try:\n",
    "        x = top_unfiltered.loc[top_unfiltered['Word']==part]\n",
    "        print(part, x[\"Count\"])\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = {\"Mouth/Lips\": 11, \"Head\": 50, \"Face\": 15, \"Hair\": 7, \"Eye(s)\": 36, \"Ear(s)\": 11, \"Foot/Feet\": 28, \"Leg(s)\": 3, \"Hand(s)\": 33 }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
