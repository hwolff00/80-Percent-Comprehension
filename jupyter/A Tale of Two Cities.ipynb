{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *A Tale of Two Cities* by Charles Dickens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five words in A Tale of Two Cities:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And</td>\n",
       "      <td>4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Of</td>\n",
       "      <td>4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To</td>\n",
       "      <td>3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count\n",
       "0  The   7996\n",
       "1  And   4999\n",
       "2   Of   4002\n",
       "3   To   3567\n",
       "4    A   2937"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "title = \"A Tale of Two Cities\"\n",
    "unfiltered = \"Two_cities.csv\"\n",
    "filtered = \"Two_cities_filtered.csv\"\n",
    "\n",
    "top_unfiltered = pd.read_csv(unfiltered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "print(f\"The top five words in {title}:\")\n",
    "top_unfiltered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top hundred ranked words (unfiltered list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.63%\n"
     ]
    }
   ],
   "source": [
    "one_hundred = top_unfiltered[:100]\n",
    "hundred_total = one_hundred[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'{str(hundred_total * 100)[:5]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overall of the 100 words: 1.03%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage overall of the 100 words: {str(((len(one_hundred)/len(top_unfiltered))*100))[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words needed for ~80% comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 750 words (rounded to nearest 25) to reach 80.24% comprehension.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>Surely</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Suppose</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>Stand</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Soul</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Son</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Count\n",
       "745   Surely     18\n",
       "746  Suppose     18\n",
       "747    Stand     18\n",
       "748     Soul     18\n",
       "749      Son     18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighty = top_unfiltered[:750]\n",
    "words = 750\n",
    "eighty_total = eighty[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'It takes {words} words (rounded to nearest 25) to reach {str(eighty_total * 100)[:5]}% comprehension.')\n",
    "eighty.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the 750 words in book: 7.74%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of the {words} words in book: {str((len(eighty)/len(top_unfiltered))*100)[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to transfer that to our filtered list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.read_csv(filtered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "#print(top.loc[top['Word']=='Suppose'])\n",
    "vocab = top[:690]\n",
    "#print(vocab.tail())\n",
    "vocab_hundred = vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons to Modern English words (according to Google's n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 A Tale of Two Cities words NOT in 100 Top Modern English Words: \n",
      "\n",
      "['Had', 'Her', 'Him', 'Said', 'She', 'Them', 'Hand', 'Into', 'Man', 'Could', 'Upon', 'Little', 'Then', 'Know', 'Down', 'Night', 'Himself', 'Before', 'Again', 'Head', 'Very', 'Day', 'Looked', 'Two', 'Father', 'Face', 'Way', 'Made', 'Long', 'Much', 'Over', 'Never', 'Good', 'Prisoner', 'Old', 'Eyes', 'Door']\n"
     ]
    }
   ],
   "source": [
    "n_gram = pd.read_csv('edited_n_gram.csv', names = [\"drop\", \"Word\", \"Count\"])\n",
    "n_gram.drop([\"drop\"], axis=1, inplace=True)\n",
    "n_gram.drop(index=[0], inplace=True)\n",
    "n_hundred= n_gram[:100]\n",
    "x = vocab_hundred.assign(hundred_in=vocab_hundred.Word.isin(n_hundred.Word).astype(int))\n",
    "h = x[x[\"hundred_in\"] == 0]\n",
    "h = list(h[\"Word\"].unique())\n",
    "print(f'Top 100 {title} words NOT in 100 Top Modern English Words: \\n\\n{h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Tale of Two Cities Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \n",
      "\n",
      " ['Himself', 'Looked', 'Father', 'Prisoner', 'Eyes', 'Door', 'Came', 'Nothing', 'Mind', 'Wine', 'Turned', 'Dear', 'Arm', 'Went', 'Took', 'Don', 'Sat', 'Wife', 'Husband', 'Sir', 'Manner', 'Hour', 'Stood', 'Moment', 'Prison', 'Dark', 'Asked', 'Saw', 'Poor', 'Cry', 'Knew', 'Voice', 'Hope', 'Brought', 'Returned', 'Woman', 'Gentleman', 'Daughter', 'Gone', 'Whom', 'Passed', 'Lay', 'Wall', 'Brother', 'Strong', 'Round', 'Madame', 'Hair', 'Corner', 'Quite', 'Heard', 'Stopped', 'Spy', 'Lady', 'Seemed', 'Myself', 'Dead', 'Toward', 'Carry', 'Mother', 'Breast', 'Speak', 'Morning', 'Held', 'Anything', 'Faces', 'Coach', 'Behind', 'Finger', 'Bed', 'Answered', 'Answer', 'Laid', 'Alone', 'Village', 'Struck', 'Stone', 'Carriage', 'Soon', 'Hold', 'Hear', 'Fellow', 'Shadow', 'Opened', 'Itself', 'Coming', 'Usual', 'Mender', 'Began', 'Lip', 'Monde', 'Ll', 'Evr√£', 'Doubt', 'Whose', 'Told', 'Passenger', 'Letter', 'Kind', 'Believe', 'Rest', 'Repeated', 'Kept', 'Feet', 'Dropped', 'Crowd', 'Citizen', 'Boy', 'Walked', 'Reason', 'Matter', 'Knitting', 'Yourself', 'Sight', 'Secret', 'Hundred', 'Guard', 'Fountain', 'Fell', 'Chair', 'Rather', 'Observed', 'Moved', 'Lost', 'Herself', 'Ground', 'Taking', 'Quiet', 'Horses', 'Hill', 'Almost', 'Spoke', 'Heavy', 'Cannot', 'Slowly', 'Morrow', 'Leave', 'Shoulder', 'Perhap', 'Lamp', 'Expression', 'Courtyard', 'Cap', 'Bear', 'Across', 'Tear', 'Sea', 'Followed', 'Ear', 'Blood', 'Ready', 'Mine', 'Confidence', 'Silence', 'Rose', 'Pretty', 'Hurry', 'Wood', 'Golden', 'Gate', 'Fear', 'Became', 'Spoken', 'Raised', 'Patriot', 'Influence', 'Glass', 'Eye', 'Earth', 'Cold', 'Clock', 'Certain', 'Shook', 'O', 'Dog', 'Danger', 'Closed', 'Appearance', 'Twenty', 'Straight', 'Standing', 'Sister', 'Rising', 'Ran', 'Object', 'Nor', 'Honour', 'Happy', 'Gave', 'Evening', 'Drinking', 'Beyond', 'Wild', 'Understand', 'Turning', 'Touch', 'Tone', 'Stair', 'Sometimes', 'Pass', 'Indeed', 'Forward', 'Fine', 'Echoes', 'Chateau', 'Bring', 'Witness', 'Thousand', 'Seat', 'Pity', 'Occasion', 'Mouth', 'Dress', 'Bright', 'Bent', 'Wish', 'Themselves', 'Showed', 'Saying', 'Remained', 'Journey', 'Creature', 'Bell', 'Afterward', 'Strange', 'Stand', 'Smile', 'Sense', 'Sake', 'Pursued', 'Purpose', 'Nephew', 'Horse', 'Foot', 'Floor', 'Felt', 'Fallen', 'Dreadful', 'Thank', 'Stones', 'Staircase', 'Sky', 'Shut', 'Seven', 'Seem', 'Passing', 'Length', 'Iron', 'Happened', 'Gentlemen', 'Gaoler', 'Forehead', 'Fancy', 'Duty', 'Die', 'Deep', 'Darkness', 'Counter', 'Aside', 'Wrong', 'Worked', 'Wind', 'Spot', 'Spirit', 'Particular', 'Otherwise', 'Mere', 'Late', 'Forth', 'Dy', 'Distance', 'Condition', 'Circumstances', 'Changed', 'Worth', 'Worn', 'Whisper', 'Soul', 'Sleep', 'Pocket', 'Miss', 'Marry', 'Lying', 'Lives', 'Jury', 'Favour', 'Fair', 'Except', 'Dust', 'Conversation', 'Colour', 'Character', 'Broken', 'Breath', 'Beside', 'Asleep', 'Appeared', 'Wore', 'Touched', 'Straw', 'Son', 'Soldier', 'Sitting', 'Released', 'Heap', 'Entered', 'Direction', 'Chamber', 'Bench', 'Attention', 'Worse', 'Ways', 'Walking', 'Vain', 'Tower', 'Thrown', 'Suddenly', 'Servant', 'Safe', 'Remarkable', 'Rain', 'Presented', 'Pieces', 'Outside', 'Lighted', 'Immediately', 'Houses', 'Honest', 'Fall', 'Emigrant', 'Drink', 'Drawing', 'Drank', 'Clothes', 'Caught', 'Bread', 'Arose', 'Wot', 'Worst', 'Wig', 'Tumbril', 'Truth', 'Tree', 'Travelling', 'Touching', 'Ten', 'Suppose', 'Softly', 'Slight', 'Silent']\n"
     ]
    }
   ],
   "source": [
    "y = vocab.assign(vocab_in=vocab.Word.isin(n_gram.Word).astype(int))\n",
    "t = y[y[\"vocab_in\"] == 0]\n",
    "t = list(t[\"Word\"].unique())\n",
    "\n",
    "print(f'{title} Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \\n\\n {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab list: 350\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocab list: {len(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall word count of book: 138015\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall word count of book: {top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.64 1.03 750 80.24 350 138015\n"
     ]
    }
   ],
   "source": [
    "print(f'{str(round(hundred_total * 100, 2))}', f'{str(round((len(one_hundred)/len(top_unfiltered))*100, 2))}', words, f'{str(round(eighty_total * 100, 2))}', f'{len(t)}', f'{top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouth 663    21\n",
      "Name: Count, dtype: int64\n",
      "Lips 353    46\n",
      "Name: Count, dtype: int64\n",
      "Head 107    177\n",
      "Name: Count, dtype: int64\n",
      "Face 98    187\n",
      "Name: Count, dtype: int64\n",
      "Hair 266    63\n",
      "Name: Count, dtype: int64\n",
      "Eyes 110    165\n",
      "Name: Count, dtype: int64\n",
      "Eye 456    34\n",
      "Name: Count, dtype: int64\n",
      "Ear 1112    12\n",
      "Name: Count, dtype: int64\n",
      "Ears 622    23\n",
      "Name: Count, dtype: int64\n",
      "Butt 5294    2\n",
      "Name: Count, dtype: int64\n",
      "Ass Series([], Name: Count, dtype: int64)\n",
      "Feet 370    44\n",
      "Name: Count, dtype: int64\n",
      "Foot 599    24\n",
      "Name: Count, dtype: int64\n",
      "Leg 3504    3\n",
      "Name: Count, dtype: int64\n",
      "Legs 1280    10\n",
      "Name: Count, dtype: int64\n",
      "Hand 70    249\n",
      "Name: Count, dtype: int64\n",
      "Hands 165    113\n",
      "Name: Count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "body = [\"Mouth\", \"Lips\", \"Head\", \"Face\", \"Hair\", \"Eyes\", \"Eye\", \"Ear\", \"Ears\", \"Butt\", \"Ass\", \"Feet\", \"Foot\", \"Leg\", \"Legs\", \"Hand\", \"Hands\"]\n",
    "\n",
    "for part in body:\n",
    "    try:\n",
    "        x = top_unfiltered.loc[top_unfiltered['Word']==part]\n",
    "        print(part, x[\"Count\"])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_cities = {\"Mouth/Lips\": 67, \"Head\": 177, \"Face\": 187, \"Hair\": 63, \"Eye(s)\": 199, \"Ear(s)\": 35, \"Butt/Ass\": 2, \"Foot/Feet\": 68, \"Leg(s)\": 13, \"Hand(s)\": 362 }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
