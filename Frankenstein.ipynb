{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Frankenstein* by Mary Shelley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five words in Frankenstein:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>4194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Of</td>\n",
       "      <td>2642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To</td>\n",
       "      <td>2094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Count\n",
       "0  The   4194\n",
       "1  And   2976\n",
       "2    I   2850\n",
       "3   Of   2642\n",
       "4   To   2094"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "title = \"Frankenstein\"\n",
    "unfiltered = \"Frankenstein.csv\"\n",
    "filtered = \"Frankenstein_filtered.csv\"\n",
    "\n",
    "top_unfiltered = pd.read_csv(unfiltered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "print(f\"The top five words in {title}:\")\n",
    "top_unfiltered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top hundred ranked words (unfiltered list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.33%\n"
     ]
    }
   ],
   "source": [
    "one_hundred = top_unfiltered[:100]\n",
    "hundred_total = one_hundred[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'{str(hundred_total * 100)[:5]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overall of the 100 words: 1.43%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage overall of the 100 words: {str(((len(one_hundred)/len(top_unfiltered))*100))[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words needed for ~80% comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 900 words (rounded to nearest 25) to reach 80.12% comprehension.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Garden</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Forms</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Forget</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Follow</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Five</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Count\n",
       "895  Garden     10\n",
       "896   Forms     10\n",
       "897  Forget     10\n",
       "898  Follow     10\n",
       "899    Five     10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighty = top_unfiltered[:900]\n",
    "words = 900\n",
    "eighty_total = eighty[\"Count\"].sum()/ top_unfiltered[\"Count\"].sum()\n",
    "print(f'It takes {words} words (rounded to nearest 25) to reach {str(eighty_total * 100)[:5]}% comprehension.')\n",
    "eighty.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the 900 words in book: 12.8%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of the {words} words in book: {str((len(eighty)/len(top_unfiltered))*100)[:4]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to transfer that to our filtered list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word  Count\n",
      "871  Five     10\n",
      "           Word  Count\n",
      "867      Gloomy     10\n",
      "868  Gentleness     10\n",
      "869      Forget     10\n",
      "870      Follow     10\n",
      "871        Five     10\n"
     ]
    }
   ],
   "source": [
    "top = pd.read_csv(filtered, names=[\"Word\", \"Count\"]).sort_values([\"Count\", \"Word\"], ascending=False).reset_index(drop=True)\n",
    "print(top.loc[top['Word']=='Five'])\n",
    "vocab = top[:872]\n",
    "print(vocab.tail())\n",
    "vocab_hundred = vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons to Modern English words (according to Google's n-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Frankenstein words NOT in 100 Top Modern English Words: \n",
      "\n",
      "['Had', 'Her', 'She', 'Him', 'Could', 'Should', 'Before', 'Myself', 'Father', 'Man', 'Them', 'Upon', 'Into', 'Friend', 'Being', 'Yet', 'Did', 'Thought', 'Life', 'Then', 'Might', 'Own', 'Eyes', 'Every', 'Feeling', 'Said', 'Shall', 'Toward', 'Saw', 'Night', 'Mind', 'Those', 'Most', 'Found', 'Heart', 'Ever']\n"
     ]
    }
   ],
   "source": [
    "n_gram = pd.read_csv('edited_n_gram.csv', names = [\"drop\", \"Word\", \"Count\"])\n",
    "n_gram.drop([\"drop\"], axis=1, inplace=True)\n",
    "n_gram.drop(index=[0], inplace=True)\n",
    "n_hundred= n_gram[:100]\n",
    "x = vocab_hundred.assign(hundred_in=vocab_hundred.Word.isin(n_hundred.Word).astype(int))\n",
    "h = x[x[\"hundred_in\"] == 0]\n",
    "h = list(h[\"Word\"].unique())\n",
    "print(f'Top 100 {title} words NOT in 100 Top Modern English Words: \\n\\n{h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \n",
      "\n",
      " ['Myself', 'Father', 'Eyes', 'Feeling', 'Toward', 'Saw', 'Mind', 'Whom', 'Felt', 'Passed', 'Dear', 'Spirit', 'Misery', 'Miserable', 'Heard', 'Became', 'Soon', 'Hour', 'Appeared', 'Mountain', 'Moment', 'Indeed', 'Horror', 'Cottage', 'Whose', 'Thus', 'Manner', 'Hope', 'Happiness', 'Fear', 'Affection', 'Despair', 'Voice', 'Cannot', 'Happy', 'Sensation', 'Scene', 'Creature', 'Alone', 'Ice', 'Joy', 'Companion', 'Came', 'Letter', 'Soul', 'Countenance', 'Wood', 'Poor', 'Entered', 'Therefore', 'Tear', 'Sometimes', 'Pleasure', 'Morning', 'Himself', 'Almost', 'Took', 'Seemed', 'Rest', 'Possessed', 'Kind', 'Journey', 'Earth', 'Delight', 'Wind', 'Gentle', 'Remain', 'Discovered', 'Continued', 'Cause', 'Object', 'Mother', 'Monster', 'Idea', 'Fiend', 'Fellow', 'Tale', 'Sea', 'Remained', 'Lost', 'Labour', 'Knew', 'Gave', 'Believe', 'Strange', 'Sight', 'Returned', 'Resolved', 'Nor', 'Heaven', 'Existence', 'Enemy', 'Beheld', 'Thousand', 'Peace', 'Passion', 'Nothing', 'Loved', 'Dream', 'Cold', 'Appearance', 'Agony', 'Reflection', 'Nearly', 'Looked', 'Grief', 'Brother', 'Arrived', 'Appear', 'Yourself', 'Placed', 'Native', 'Mine', 'Lay', 'Endeavoured', 'Desire', 'Dark', 'Brought', 'Began', 'Rather', 'Occupy', 'Murderer', 'Length', 'Kindness', 'Hardly', 'Greatest', 'Beautiful', 'Wonder', 'Stranger', 'Sister', 'Quickly', 'Perceived', 'Lovely', 'Imagination', 'Ground', 'Expressed', 'Evil', 'Attention', 'Spoke', 'Spent', 'Seek', 'Sat', 'Rage', 'Greater', 'Dy', 'Door', 'Discovery', 'Desired', 'Creatures', 'Cousin', 'Wretch', 'Woman', 'Turned', 'Revenge', 'Path', 'Pain', 'Fixed', 'Die', 'Degree', 'Cottager', 'Beloved', 'Wretched', 'Wish', 'Sympathy', 'Suddenly', 'Longer', 'Lived', 'Hopes', 'Filled', 'Endured', 'Destroyed', 'Dead', 'Concerning', 'Anguish', 'Sweet', 'Quitted', 'Promise', 'Murder', 'Itself', 'Followed', 'Duty', 'Youth', 'Vengeance', 'Unable', 'Suffered', 'Spot', 'Sleep', 'Observed', 'Moon', 'Leave', 'Formed', 'Destruction', 'Creation', 'Cloud', 'Bound', 'Answer', 'Wished', 'Went', 'Victim', 'Vessel', 'Trees', 'Sufficient', 'Pursuit', 'Perhap', 'Murdered', 'Ill', 'Entirely', 'Dã', 'Drew', 'Destroy', 'Deeply', 'Conversation', 'Calm', 'Allowed', 'Acquainted', 'Task', 'Suffering', 'Sorrow', 'Son', 'Satisfy', 'Sank', 'Progress', 'Occupation', 'Mon', 'Learned', 'Innocent', 'Forth', 'Exclaimed', 'Endeavour', 'Deep', 'Dared', 'Cry', 'Creator', 'Boat', 'Blood', 'Approached', 'Unhappy', 'Thy', 'Surrounded', 'Sought', 'Snow', 'Secret', 'Rendered', 'Reflect', 'Purpose', 'Proceeded', 'Opened', 'Necessary', 'Melancholy', 'Lip', 'Led', 'Innocence', 'Fell', 'Fate', 'Eye', 'Engaged', 'Endure', 'Easily', 'Determined', 'Departure', 'Covered', 'Courage', 'Continually', 'Consolation', 'Wonderful', 'Visited', 'Speak', 'Retired', 'Quit', 'Pursue', 'Misfortunes', 'Expression', 'Danger', 'Afterward', 'Across', 'Wept', 'Walked', 'Union', 'Understand', 'Sky', 'Shore', 'Seized', 'Scenes', 'Rose', 'Restored', 'Rain', 'Pass', 'Overcome', 'Names', 'Misfortune', 'Instrument', 'Instantly', 'Hear', 'Extreme', 'Effect', 'Discover', 'Dearest', 'Crime', 'Bitter', 'Bed', 'Asked', 'Wild', 'Voyage', 'Unfortunate', 'Toil', 'Strength', 'Solitude', 'Smiles', 'Silent', 'Reflected', 'Prospect', 'Presence', 'Philosophy', 'Marriage', 'Limb', 'Hovel', 'Horrible', 'Distance', 'Desert', 'Describe', 'Departed', 'Daughter', 'Awoke', 'Arm', 'Accompany', 'Wretchedness', 'Waves', 'Wandered', 'Understood', 'Truth', 'Tranquillity', 'Told', 'Thou', 'Thirst', 'Silence', 'Render', 'Remorse', 'Recovered', 'Reason', 'Protector', 'Paused', 'Moved', 'Instant', 'Ideas', 'Herself', 'Hatred', 'Frame', 'Forward', 'Former', 'Fancy', 'Devoted', 'Darkness', 'Curiosity', 'Circumstances', 'Capable', 'Bestow', 'Benevolent', 'Amiable', 'Agitation', 'Admiration', 'Watching', 'Vain', 'Undertaking', 'Threw', 'Surprised', 'Summit', 'Sledge', 'Situation', 'Servant', 'Scarcely', 'Remembered', 'Pursued', 'Promised', 'Prison', 'Presented', 'Pity', 'Parent', 'Ought', 'Mighty', 'Magistrate', 'Latter', 'Hill', 'Gone', 'Gained', 'Frightful', 'Feet', 'Feared', 'Favourite', 'Exertion', 'Excellent', 'Enjoyed', 'Employed', 'Doubt', 'Disposition', 'Directed', 'Difficulty', 'Dare', 'Crimes', 'Commence', 'Cheek', 'Carry', 'Bestowed', 'Believed', 'Attempt', 'Ardour', 'Animal', 'Allow', 'Addressed', 'Winter', 'Weep', 'Virtue', 'Village', 'Torture', 'Themselves', 'Success', 'Spring', 'Sense', 'Season', 'Recollection', 'Professor', 'Produced', 'Pleasant', 'Occasion', 'Obliged', 'Master', 'Listened', 'Lady', 'Justice', 'Inhabitant', 'Increased', 'Hunger', 'Hitherto', 'Greatly', 'Fled', 'Fatigue', 'Fair', 'Expected', 'Excited', 'Evening', 'Ear', 'Dreadful', 'Divine', 'Degrees', 'Consent', 'Conceived', 'Committed', 'Cheerful', 'Cast', 'Broken', 'Branches', 'Behold', 'Arrive', 'Apply', 'Wife', 'Warmth', 'Vast', 'Utterly', 'Utter', 'Trial', 'Trembled', 'Threat', 'Terror', 'Superior', 'Suffer', 'Specy', 'Shut', 'Ruin', 'Round', 'Reality', 'Rapidly', 'Peasant', 'Ocean', 'Noble', 'Mankind', 'Longed', 'Leaves', 'Incident', 'Honour', 'Hair', 'Guilty', 'Gloom', 'Gazed', 'Fresh', 'Experienced', 'Except', 'Eternal', 'Enthusiasm', 'Enjoyment', 'Emotion', 'Dry', 'Devil', 'Detail', 'Destiny', 'Demand', 'Considered', 'Condemned', 'Compassion', 'Certainly', 'Ceased', 'Beneath', 'Behind', 'Assured', 'Afford', 'Accident', 'Abhorred', 'Violence', 'Thee', 'Terrible', 'Surely', 'Supposed', 'Struck', 'Stream', 'Storm', 'Stood', 'Solitary', 'Sides', 'Shone', 'Sailor', 'Sad', 'Rushed', 'Returning', 'Resolution', 'Residence', 'Repose', 'Remembrance', 'Procure', 'Pressed', 'Poverty', 'Persuade', 'Modern', 'Lover', 'Listen', 'Instead', 'Ignorant', 'Hurry', 'Hideous', 'Hell', 'Guilt', 'Gloomy', 'Gentleness', 'Forget', 'Follow']\n"
     ]
    }
   ],
   "source": [
    "y = vocab.assign(vocab_in=vocab.Word.isin(n_gram.Word).astype(int))\n",
    "t = y[y[\"vocab_in\"] == 0]\n",
    "t = list(t[\"Word\"].unique())\n",
    "\n",
    "print(f'{title} Vocab List Words NOT in Top 1000 Modern Words (names/locations excluded): \\n\\n {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab list: 542\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocab list: {len(t)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall word count of book: 75265\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall word count of book: {top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.33 1.43 900 80.13 542 75265\n"
     ]
    }
   ],
   "source": [
    "print(f'{str(round(hundred_total * 100, 2))}', f'{str(round((len(one_hundred)/len(top_unfiltered))*100, 2))}', words, f'{str(round(eighty_total * 100, 2))}', f'{len(t)}', f'{top_unfiltered[\"Count\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouth Series([], Name: Count, dtype: int64)\n",
      "Lips 502    18\n",
      "Name: Count, dtype: int64\n",
      "Head 352    25\n",
      "Name: Count, dtype: int64\n",
      "Face 444    20\n",
      "Name: Count, dtype: int64\n",
      "Hair 1109    8\n",
      "Name: Count, dtype: int64\n",
      "Eyes 80    104\n",
      "Name: Count, dtype: int64\n",
      "Eye 509    18\n",
      "Name: Count, dtype: int64\n",
      "Ear 2132    4\n",
      "Name: Count, dtype: int64\n",
      "Ears 1127    8\n",
      "Name: Count, dtype: int64\n",
      "Butt Series([], Name: Count, dtype: int64)\n",
      "Ass 3921    2\n",
      "Name: Count, dtype: int64\n",
      "Feet 686    13\n",
      "Name: Count, dtype: int64\n",
      "Foot 1723    5\n",
      "Name: Count, dtype: int64\n",
      "Leg Series([], Name: Count, dtype: int64)\n",
      "Legs Series([], Name: Count, dtype: int64)\n",
      "Hand 334    26\n",
      "Name: Count, dtype: int64\n",
      "Hands 207    38\n",
      "Name: Count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "body = [\"Mouth\", \"Lips\", \"Head\", \"Face\", \"Hair\", \"Eyes\", \"Eye\", \"Ear\", \"Ears\", \"Butt\", \"Ass\", \"Feet\", \"Foot\", \"Leg\", \"Legs\", \"Hand\", \"Hands\"]\n",
    "\n",
    "for part in body:\n",
    "    try:\n",
    "        x = top_unfiltered.loc[top_unfiltered['Word']==part]\n",
    "        print(part, x[\"Count\"])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein = {\"Mouth/Lips\": 18, \"Head\": 25, \"Face\": 20, \"Hair\": 8, \"Eye(s)\": 122, \"Ear(s)\": 12, \"Butt/Ass\": 2, \"Foot/Feet\": 18, \"Hand(s)\": 64 }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
